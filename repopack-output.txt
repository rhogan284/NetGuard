================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-09-03T08:35:10.562Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
db/init.sql
docker-compose.yml
locust/locustfile.py
locust/threat_locustfile.py
logstash/logstash.conf
logstash/logstash.yml
threat_detector/Dockerfile
threat_detector/requirements.txt
threat_detector/threat_detector.py
web/app.py
web/Dockerfile
web/requirements.txt

================================================================
Repository Files
================================================================

================
File: db/init.sql
================
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    price DECIMAL(10, 2) NOT NULL
);

INSERT INTO products (name, price) VALUES
    ('Laptop', 999.99),
    ('Smartphone', 599.99),
    ('Headphones', 149.99);

================
File: docker-compose.yml
================
services:
  web:
    build: ./web
    ports:
      - "5002:5000"
    depends_on:
      - db
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/ecommerce

  db:
    image: postgres:13
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ecommerce
    volumes:
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    environment:
      - discovery.type=single-node
      - logger.level=WARN
    ports:
      - "9200:9200"
    healthcheck:
      test: [ "CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:7.14.0
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - ./logstash/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logs:/mnt/logs
    depends_on:
      - elasticsearch
    ports:
      - "5044:5044"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - LOGGING_ROOT_LEVEL=warn
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  locust:
    image: locustio/locust
    ports:
      - "8089:8089"
    volumes:
      - ./locust:/mnt/locust
      - ./logs:/mnt/logs
    command: -f /mnt/locust/locustfile.py --host http://web:5000 --logfile /mnt/logs/locust.log --loglevel INFO
    depends_on:
      - web

  threat-locust:
    image: locustio/locust
    ports:
      - "8090:8089"
    volumes:
      - ./locust:/mnt/locust
      - ./logs:/mnt/logs
    command: -f /mnt/locust/threat_locustfile.py --host http://web:5000 --logfile /mnt/logs/threat_locust.log --loglevel INFO
    depends_on:
      - web

  threat-detector:
    build: ./threat_detector
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
    volumes:
      - ./logs:/mnt/logs
    restart: unless-stopped

volumes:
  logs:

================
File: locust/locustfile.py
================
import random
import json
import logging
import time
import uuid
from locust import HttpUser, task, between
from locust.contrib.fasthttp import FastHttpUser
from datetime import datetime

json_logger = logging.getLogger('json_logger')
json_logger.setLevel(logging.INFO)
json_handler = logging.FileHandler('/mnt/logs/locust_json.log')
json_handler.setFormatter(logging.Formatter('%(message)s'))
json_logger.addHandler(json_handler)

class WebsiteUser(FastHttpUser):
    wait_time = between(1, 5)

    def on_start(self):
        self.user_id = str(uuid.uuid4())
        self.session_id = str(uuid.uuid4())
        self.client_ip = f"{random.randint(1, 223)}.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 254)}"
        self.user_agent = random.choice([
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (iPad; CPU OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Linux; Android 11; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Mobile Safari/537.36'
        ])
        self.geolocation = random.choice([
            {"country": "United States", "city": "New York", "timezone": "America/New_York"},
            {"country": "United Kingdom", "city": "London", "timezone": "Europe/London"},
            {"country": "Japan", "city": "Tokyo", "timezone": "Asia/Tokyo"},
            {"country": "Australia", "city": "Sydney", "timezone": "Australia/Sydney"},
            {"country": "Germany", "city": "Berlin", "timezone": "Europe/Berlin"}
        ])

    @task(10)
    def index_page(self):
        self._log_request("GET", "/", None)

    @task(5)
    def view_product(self):
        product_id = random.randint(1, 10)
        self._log_request("GET", f"/products/{product_id}", None)

    @task(2)
    def add_to_cart(self):
        product_id = random.randint(1, 10)
        self._log_request("POST", "/cart", {"product_id": product_id, "quantity": 1})

    @task(2)
    def view_cart(self):
        self._log_request("GET", "/cart", None)

    @task(1)
    def checkout(self):
        self._log_request("POST", "/checkout", {"payment_method": "credit_card"})

    def _log_request(self, method, path, data):
        log_id = str(uuid.uuid4())
        start_time = time.time()
        try:
            if method == "GET":
                response = self.client.get(path)
            elif method == "POST":
                response = self.client.post(path, json=data)
            else:
                raise ValueError(f"Unsupported HTTP method: {method}")

            self._log_response(log_id, method, path, response, start_time, data)
        except Exception as e:
            self._log_exception(log_id, method, path, e, start_time, data)

    def _log_response(self, log_id, method, path, response, start_time, data):
        log_entry = {
            "log_id": log_id,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": response.status_code,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "bytes_sent": len(response.request.body) if response.request.body else 0,
            "bytes_received": len(response.content),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com"]),
            "request_headers": dict(response.request.headers),
            "response_headers": dict(response.headers),
            "geo": self.geolocation,
            "request_body": data if data else None
        }
        json_logger.info(json.dumps(log_entry))

    def _log_exception(self, log_id, method, path, exception, start_time, data):
        log_entry = {
            "log_id": log_id,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": 500,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "exception": str(exception),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com", "https://example.com"]),
            "geo": self.geolocation,
            "request_body": data if data else None
        }
        json_logger.info(json.dumps(log_entry))

================
File: locust/threat_locustfile.py
================
import random
import json
import logging
import time
import uuid
from locust import HttpUser, task, between
from locust.contrib.fasthttp import FastHttpUser
from datetime import datetime

json_logger = logging.getLogger('json_logger')
json_logger.setLevel(logging.INFO)
json_handler = logging.FileHandler('/mnt/logs/threat_locust_json.log')
json_handler.setFormatter(logging.Formatter('%(message)s'))
json_logger.addHandler(json_handler)

class MaliciousUser(FastHttpUser):
    wait_time = between(1, 10)

    def on_start(self):
        self.user_id = str(uuid.uuid4())
        self.session_id = str(uuid.uuid4())
        self.client_ip = f"{random.randint(1, 223)}.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 254)}"
        self.user_agent = random.choice([
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',
            'Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)',
            'sqlmap/1.4.7#stable (http://sqlmap.org)',
            'Nikto/2.1.6',
            'Acunetix-WebVulnerability-Scanner/1.0',
        ])
        self.geolocation = random.choice([
            {"country": "Russia", "city": "Moscow", "timezone": "Europe/Moscow"},
            {"country": "China", "city": "Beijing", "timezone": "Asia/Shanghai"},
            {"country": "United States", "city": "Ashburn", "timezone": "America/New_York"},
            {"country": "Netherlands", "city": "Amsterdam", "timezone": "Europe/Amsterdam"},
        ])

    @task(2)
    def sql_injection_attempt(self):
        payloads = [
            "' OR '1'='1",
            "' UNION SELECT username, password FROM users--",
            "admin'--",
            "1; DROP TABLE users--",
            "' OR 1=1--",
        ]
        payload = random.choice(payloads)
        self._log_request("GET", f"/products?id={payload}", None, "sql_injection")

    @task(2)
    def xss_attempt(self):
        payloads = [
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "javascript:alert('XSS')",
            "<svg onload=alert('XSS')>",
            "'\"><script>alert('XSS')</script>",
        ]
        payload = random.choice(payloads)
        self._log_request("POST", "/search", {"q": payload}, "xss")

    @task(3)
    def brute_force_login(self):
        usernames = ['admin', 'root', 'user', 'test', 'guest']
        passwords = ['password', '123456', 'admin', 'qwerty', 'letmein']
        username = random.choice(usernames)
        password = random.choice(passwords)
        self._log_request("POST", "/login", {"username": username, "password": password}, "brute_force")

    @task(1)
    def path_traversal_attempt(self):
        payloads = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\win.ini",
            "....//....//....//etc/hosts",
            "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",
            "..%252f..%252f..%252fetc%252fpasswd",
        ]
        payload = random.choice(payloads)
        self._log_request("GET", f"/static/{payload}", None, "path_traversal")

    @task(1)
    def command_injection_attempt(self):
        payloads = [
            "; cat /etc/passwd",
            "& ipconfig",
            "| ls -la",
            "`whoami`",
            "$(echo 'vulnerable')",
        ]
        payload = random.choice(payloads)
        self._log_request("GET", f"/exec?cmd=date{payload}", None, "command_injection")

    @task(2)
    def ddos_simulation(self):
        endpoints = ['/', '/products', '/cart', '/checkout', '/search']
        for _ in range(random.randint(5, 15)):
            endpoint = random.choice(endpoints)
            self._log_request("GET", endpoint, None, "ddos")

    def _log_request(self, method, path, data, threat_type):
        log_id = str(uuid.uuid4())
        start_time = time.time()
        try:
            if method == "GET":
                response = self.client.get(path)
            elif method == "POST":
                response = self.client.post(path, json=data)
            else:
                raise ValueError(f"Unsupported HTTP method: {method}")

            self._log_response(log_id, method, path, response, start_time, data, threat_type)
        except Exception as e:
            self._log_exception(log_id, method, path, e, start_time, data, threat_type)

    def _log_response(self, log_id, method, path, response, start_time, data, threat_type):
        log_entry = {
            "log_id": log_id,
            "threat_type": threat_type,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": response.status_code,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "bytes_sent": len(response.request.body) if response.request.body else 0,
            "bytes_received": len(response.content),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com", "https://example.com"]),
            "request_headers": dict(response.request.headers),
            "response_headers": dict(response.headers),
            "geo": self.geolocation,
            "request_body": data if data else None,
        }
        json_logger.info(json.dumps(log_entry))

    def _log_exception(self, log_id, method, path, exception, start_time, data, threat_type):
        log_entry = {
            "log_id": log_id,
            "threat_type": threat_type,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": 500,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "exception": str(exception),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com", "https://example.com"]),
            "geo": self.geolocation,
            "request_body": data if data else None,
        }
        json_logger.info(json.dumps(log_entry))

================
File: logstash/logstash.conf
================
input {
  file {
    path => "/mnt/logs/locust_json.log"
    start_position => "beginning"
    codec => json
    type => "normal"
  }
  file {
    path => "/mnt/logs/threat_locust_json.log"
    start_position => "beginning"
    codec => json
    type => "threat"
  }
}

filter {
  date {
    match => [ "@timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS" ]
    target => "@timestamp"
  }

  mutate {
    convert => {
      "bytes_received" => "integer"
      "bytes_sent" => "integer"
      "response_time_ms" => "integer"
      "status_code" => "integer"
    }
    remove_field => [ "host" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "locust-logs-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}

================
File: logstash/logstash.yml
================
log.level: warn

================
File: threat_detector/Dockerfile
================
FROM python:3.12
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY threat_detector.py .

# Create the logs directory
RUN mkdir -p /mnt/logs && chmod 777 /mnt/logs

CMD ["python", "threat_detector.py"]

================
File: threat_detector/requirements.txt
================
elasticsearch==8.9.0

================
File: threat_detector/threat_detector.py
================
import json
import re
from collections import defaultdict
from datetime import datetime, timezone, timedelta
from elasticsearch import Elasticsearch
import time
import os
import logging
import uuid
from urllib3.exceptions import NewConnectionError
from elasticsearch.exceptions import ConnectionError as ElasticsearchConnectionError

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

log_dir = '/mnt/logs'
os.makedirs(log_dir, exist_ok=True)

threat_logger = logging.getLogger('threat_logger')
threat_logger.setLevel(logging.WARNING)
file_handler = logging.FileHandler(os.path.join(log_dir, 'detected_threats.log'))
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
threat_logger.addHandler(file_handler)


class ThreatDetector:
    def __init__(self):
        self.es = None
        self.connect_to_elasticsearch()
        self.detection_rules = {
            "sql_injection": [
                r"id=\s*['\"].*?(?:--|\%27|')",  # Basic SQL injection
                r"UNION\s+SELECT",  # UNION-based SQL injection
                r"EXEC\s*\(",  # Execution of stored procedures
                r"WAITFOR\s+DELAY",  # Time-based SQL injection
                r"SELECT\s+.*?FROM",  # SELECT statements
                r"1\s*=\s*1",  # Tautologies
                r"DROP\s+TABLE",  # Table dropping attempts
                r";.*?(?:SELECT|INSERT|UPDATE|DELETE|DROP)"  # Piggybacked queries
            ],
            "xss": [
                r"<script>",  # Basic XSS
                r"javascript:",  # JavaScript protocol
                r"alert\s*\(",  # Alert functions
                r"on\w+\s*=",  # Event handlers
                r"<svg.*?on\w+\s*=",  # SVG-based XSS
                r"<img.*?on\w+\s*=",  # Image-based XSS
                r"\"\s*><script>",  # Quote breaking XSS
                r"'\s*><script>"  # Single quote breaking XSS
            ],
            "path_traversal": [
                r"\.\.\/",  # Unix-style path traversal
                r"\.\.\\",  # Windows-style path traversal
                r"\.\.%2f",  # URL encoded ../
                r"\.\.%5c",  # URL encoded ..\
                r"%2e%2e%2f",  # Double URL encoded ../
                r"%252e%252e%252f",  # Triple URL encoded ../
                r"\.\.(?:%2f|%5c|/|\\)",  # Mixed encoding: '..' followed by encoded or raw slash
                r"(?:%2e|%252e){2,}(?:%2f|%5c|/|\\)"  # Multiple encoded dots followed by encoded or raw slash
            ],
            "command_injection": [
                r";\s*\w+",  # Command chaining with semicolon
                r"`.*?`",  # Backtick execution
                r"\|\s*\w+",  # Pipe to command
                r"\$\(.*?\)",  # Command substitution
                r"&&\s*\w+",  # Command chaining with &&
                r"\|\|\s*\w+"  # Command chaining with ||
            ],
            "ddos": [
                r"/",  # Homepage
                r"/login",  # Login page
                r"/search",  # Search functionality
                r"/products",  # Product listing
                r"/cart",  # Shopping cart
                r"/checkout"  # Checkout process
            ]
        }
        self.compiled_rules = self.compile_rules()
        self.request_timestamps = defaultdict(list)
        self.ddos_threshold = 5
        self.ddos_time_window = 2
        self.source_index = "locust-logs-*"
        self.threat_index = "threat-logs"
        self.normal_index = "normal-logs"
        self.last_processed_timestamp = self.get_last_processed_timestamp()

    def get_last_processed_timestamp(self):
        try:
            with open('/mnt/logs/last_processed_timestamp.txt', 'r') as f:
                return datetime.fromisoformat(f.read().strip())
        except FileNotFoundError:
            return datetime.now(timezone.utc) - timedelta(minutes=5)

    def save_last_processed_timestamp(self, timestamp):
        with open('/mnt/logs/last_processed_timestamp.txt', 'w') as f:
            f.write(timestamp.isoformat())

    def connect_to_elasticsearch(self):
        max_retries = 5
        retry_delay = 10

        for attempt in range(max_retries):
            try:
                self.es = Elasticsearch([
                    f"http://{os.environ.get('ELASTICSEARCH_HOST', 'elasticsearch')}:{os.environ.get('ELASTICSEARCH_PORT', '9200')}"])
                self.es.info()
                print("Successfully connected to Elasticsearch")
                return
            except (NewConnectionError, ElasticsearchConnectionError) as e:
                print(f"Connection attempt {attempt + 1} failed: {str(e)}")
                if attempt < max_retries - 1:
                    print(f"Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                else:
                    print("Max retries reached. Unable to connect to Elasticsearch.")
                    raise

    def compile_rules(self):
        compiled_rules = {}
        for threat_type, patterns in self.detection_rules.items():
            compiled_rules[threat_type] = [re.compile(pattern, re.IGNORECASE) for pattern in patterns]
        return compiled_rules

    def detect_threats(self, log_entry):
        threats = set()
        url = log_entry.get('url', '')
        method = log_entry.get('method', '')
        request_body = json.dumps(log_entry.get('request_body', {}))
        headers = json.dumps(log_entry.get('request_headers', {}))
        client_ip = log_entry.get('client_ip', '')
        timestamp = datetime.fromisoformat(log_entry.get('@timestamp'))

        content_to_check = f"{url} {request_body} {headers}"

        for threat_type, patterns in self.compiled_rules.items():
            if threat_type != "ddos":
                for pattern in patterns:
                    if pattern.search(content_to_check):
                        threats.add(threat_type)
                        break

        if method == 'POST' and '/login' in url:
            threats.add('potential_brute_force')

        if '/exec' in url and 'cmd' in url:
            threats.add('command_injection')

        # DDoS detection
        self.request_timestamps[client_ip].append(timestamp)

        self.request_timestamps[client_ip] = [
            ts for ts in self.request_timestamps[client_ip]
            if timestamp - ts <= timedelta(seconds=self.ddos_time_window)
        ]

        if len(self.request_timestamps[client_ip]) > 1:
            if len(self.request_timestamps[client_ip]) > self.ddos_threshold:
                threats.add('ddos')
            else:
                threats.add('potential_ddos')

        return list(threats)

    def reorder_log_fields(self, log_entry):
        field_order = [
            "log_id",
            "threat_type",
            "@timestamp",
            "client_ip",
            "method",
            "url",
            "status_code",
            "response_time_ms",
            "bytes_sent",
            "bytes_received",
            "user_agent",
            "referer",
            "request_headers",
            "response_headers",
            "geo",
            "request_body",
            "detected_threats"
        ]

        ordered_log = {}
        for field in field_order:
            if field in log_entry:
                ordered_log[field] = log_entry[field]
            elif field == "log_id":
                ordered_log[field] = str(uuid.uuid4())
            elif field == "threat_type":
                ordered_log[field] = log_entry.get("type", "unknown")

        for key, value in log_entry.items():
            if key not in ordered_log:
                ordered_log[key] = value

        return ordered_log

    def process_log(self, log_entry):
        threats = self.detect_threats(log_entry)
        reordered_log = self.reorder_log_fields(log_entry)

        if threats:
            reordered_log['detected_threats'] = threats
            self.es.index(index=self.threat_index, document=reordered_log)
            threat_message = f"Threat detected: {threats} in log: {reordered_log.get('url', 'N/A')} from IP: {reordered_log.get('client_ip', 'N/A')}"
            logger.warning(threat_message)
            threat_logger.warning(json.dumps(reordered_log))
        else:
            self.es.index(index=self.normal_index, document=reordered_log)
            logger.info(
                f"Normal log processed: {reordered_log.get('url', 'N/A')} from IP: {reordered_log.get('client_ip', 'N/A')}")

    def get_new_logs(self):
        query = {
            "bool": {
                "must": [
                    {
                        "range": {
                            "@timestamp": {
                                "gt": self.last_processed_timestamp.isoformat()
                            }
                        }
                    }
                ]
            }
        }

        result = self.es.search(index=self.source_index, query=query, sort=[{"@timestamp": "asc"}], size=10000)
        logger.info(f"Retrieved {len(result['hits']['hits'])} new logs from Elasticsearch")
        return result['hits']['hits']

    def run(self):
        while True:
            try:
                logs = self.get_new_logs()
                for log in logs:
                    self.process_log(log['_source'])
                    log_timestamp = datetime.fromisoformat(log['_source']['@timestamp'].replace('Z', '+00:00'))
                    self.last_processed_timestamp = max(self.last_processed_timestamp, log_timestamp)

                if logs:
                    self.save_last_processed_timestamp(self.last_processed_timestamp)
                    logger.info(
                        f"Processed {len(logs)} logs. Last processed timestamp: {self.last_processed_timestamp.isoformat()}")
                else:
                    logger.info("No new logs to process.")

                time.sleep(5)
            except Exception as e:
                logger.error(f"An error occurred: {str(e)}")
                logger.info("Attempting to reconnect to Elasticsearch...")
                self.connect_to_elasticsearch()


if __name__ == "__main__":
    detector = ThreatDetector()
    detector.run()

================
File: web/app.py
================
from flask import Flask, request, jsonify
import psycopg2
import os

app = Flask(__name__)

def get_db_connection():
    conn = psycopg2.connect(os.environ['DATABASE_URL'])
    return conn

@app.route('/')
def hello():
    return "Welcome to the E-commerce Platform Simulation!"

@app.route('/products')
def get_products():
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute('SELECT * FROM products;')
    products = cur.fetchall()
    cur.close()
    conn.close()
    return jsonify([{'id': p[0], 'name': p[1], 'price': p[2]} for p in products])

@app.route('/products/<int:product_id>')
def get_product(product_id):
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute('SELECT * FROM products WHERE id = %s;', (product_id,))
    product = cur.fetchone()
    cur.close()
    conn.close()
    if product:
        return jsonify({'id': product[0], 'name': product[1], 'price': product[2]})
    return jsonify({"error": "Product not found"}), 404

@app.route('/login', methods=['POST'])
def login():
    # Simulate login (no actual authentication)
    return jsonify({"message": "Login simulation successful"})

@app.route('/cart', methods=['GET', 'POST'])
def cart():
    if request.method == 'POST':
        # Simulate adding to cart
        return jsonify({"message": "Item added to cart"})
    else:
        # Simulate viewing cart
        return jsonify({"message": "Cart viewed"})

@app.route('/checkout', methods=['POST'])
def checkout():
    return jsonify({"message": "Checkout process completed"})

@app.route('/search')
def search():
    query = request.args.get('q', '')
    # Simulate search results
    return jsonify({"message": f"Search results for: {query}"})


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)

================
File: web/Dockerfile
================
FROM python:3.12
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY app.py .
CMD ["python", "app.py"]

================
File: web/requirements.txt
================
Flask==3.0.3
psycopg2-binary==2.9.9
